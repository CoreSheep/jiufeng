<!DOCTYPE html>
<html lang="en" itemscope itemtype="http://schema.org/WebPage">
  <head>
    
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">


<title>Defeating Nondeterminism in LLM Inference: A Breakthrough in Deep Learning System Reproducibility - Feng</title>
<meta name="description" content="An in-depth analysis of how the Thinking Machines team solved the nondeterminism problem in large language model inference, achieving truly reproducible reasoning.">
<script type="application/ld+json">
{
    "@context": "http://schema.org",
    "@type": "WebSite",
    "name": "Feng",
    
    "url": "https:\/\/jiufengblog.firebaseapp.com\/"
}
</script><script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "Organization",
  "name": "",
  "url": "https:\/\/jiufengblog.firebaseapp.com\/"
  
  
  
  
}
</script>
<script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [{
        "@type": "ListItem",
        "position": 1,
        "item": {
          "@id": "https:\/\/jiufengblog.firebaseapp.com\/",
          "name": "home"
        }
    },{
        "@type": "ListItem",
        "position": 3,
        "item": {
          "@id": "https:\/\/jiufengblog.firebaseapp.com\/blogs\/2025\/sep\/defeating-llm-nondeterminism\/",
          "name": "Defeating nondeterminism in llm inference a breakthrough in deep learning system reproducibility"
        }
    }]
}
</script><script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "Article",
  "author": {
    "name" : ""
  },
  "headline": "Defeating Nondeterminism in LLM Inference: A Breakthrough in Deep Learning System Reproducibility",
  "description" : "An in-depth analysis of how the Thinking Machines team solved the nondeterminism problem in large language model inference, achieving truly reproducible reasoning.",
  "inLanguage" : "en",
  "wordCount":  1110 ,
  "datePublished" : "2025-09-15T10:00:00",
  "dateModified" : "2025-09-15T10:00:00",
  "image" : "https:\/\/jiufengblog.firebaseapp.com\/",
  "keywords" : [ "machine-learning, llm, determinism, reproducibility, research" ],
  "mainEntityOfPage" : "https:\/\/jiufengblog.firebaseapp.com\/blogs\/2025\/sep\/defeating-llm-nondeterminism\/",
  "publisher" : {
    "@type": "Organization",
    "name" : "https:\/\/jiufengblog.firebaseapp.com\/",
    "logo" : {
        "@type" : "ImageObject",
        "url" : "https:\/\/jiufengblog.firebaseapp.com\/",
        "height" :  60 ,
        "width" :  60
    }
  }
}
</script>

<meta property="og:title" content="Defeating Nondeterminism in LLM Inference: A Breakthrough in Deep Learning System Reproducibility" />
<meta property="og:description" content="An in-depth analysis of how the Thinking Machines team solved the nondeterminism problem in large language model inference, achieving truly reproducible reasoning.">
<meta property="og:url" content="https://jiufengblog.firebaseapp.com/blogs/2025/sep/defeating-llm-nondeterminism/" />
<meta property="og:type" content="website" />
<meta property="og:site_name" content="Feng" />
<link rel="apple-touch-icon" sizes="180x180" href=" https://jiufengblog.firebaseapp.com/favicon/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://jiufengblog.firebaseapp.com/favicon/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="https://jiufengblog.firebaseapp.com/favicon/favicon-16x16.png">


<meta name="generator" content="Hugo 0.136.5">
<link rel="alternate" href="https://jiufengblog.firebaseapp.com/index.xml" type="application/rss+xml" title="Feng">
<script src="https://jiufengblog.firebaseapp.com/js/dark-mode.js"></script><script src="https://jiufengblog.firebaseapp.com/vendor/lunr/lunr.min.js"></script><script src="https://jiufengblog.firebaseapp.com/js/lunr-search.js" data-index="/search.json"></script><link rel="stylesheet" href="/style.min.css">







  </head>
  <body>
    
<div class="container fixed-top mw-100">
  <div class="row justify-content-center">
    <div class="col-sm-12 col-md-12 col-lg-10 col-xl-10">

      <nav class="navbar navbar-expand-lg navbar-light fixed-top p-0">
        <div class="container">

          <a class="navbar-brand fw-bold" href="https://jiufengblog.firebaseapp.com/">Feng</a>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav"
            aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
          </button>

          <div class="collapse navbar-collapse justify-content-end" id="navbarNav">
            <ul class="navbar-nav mb-2 mb-lg-0 align-items-baseline">
              
              

              <li class="nav-item">
                
                
                
                

                <a class="nav-link " title="Home"
                  href="/"> Home</a>
              </li>

              
              
              

              <li class="nav-item">
                
                
                
                

                <a class="nav-link  active " title="Blogs"
                  href="/blogs/"> Blogs</a>
              </li>

              
              
              

              <li class="nav-item">
                
                
                
                

                <a class="nav-link " title="About"
                  href="/about/"> About</a>
              </li>

              
              


                
            

            
              <li class="nav-item nav-link">
                <a id="dark-mode-toggle" class="bi bi-moon-stars" role="button"></a>
              </li>

              
              
              <li class="nav-item search-item">
                <form id="search" class="search" role="search">
                  <label for="search-input" class="bi bi-search search-icon"></label>
                  <input type="search" id="search-input" class="search-input">
                </form>
              </li>
              
            </ul>

            
            <template id="search-heading" hidden data-results-none=""
              data-results-one=""
              data-results-many="">
              <div class="row">
                <div class="col-lg-8 offset-lg-2 col-md-10 offset-md-1 ">
                  <h1 id="search-title" class="search-title"></h1>
                </div>
              </div>
            </template>

            <template id="search-result" hidden>
              <div class="row">
                <div class="col-lg-8 offset-lg-2 col-md-10 offset-md-1 ">
                  <article class="content post">
                    <h2><a class="summary-title-link"></a></h2>
                    <div class="post-entry"></div>
                    <div class="read-more-section">
                      <h6 class="text-muted link-underline">
                        <a class="read-more-link">
                          Read More
                          <i class="bi bi-arrow-right"></i>
                        </a>
                      </h6>
                    </div>
                  </article>
                </div>
              </div>
            </template>
            
          </div>
        </div>
      </nav>

    </div>
  </div>
</div>
    









<header class="header-section ">

  <div class="intro-header no-img mt-10">
    <div class="container">
      <div class="row justify-content-center">
        
        <div class="col-sm-12 col-md-12 col-lg-8 col-xl-8">
          

          
          <div class="col-sm-12 col-md-12 col-lg-12 col-xl-12">
            

            <div class="blogs-heading">
              

              

              
              <h1 class="fw-semibold display-5 lh-1 mb-3"> 
                Defeating Nondeterminism in LLM Inference: A Breakthrough in Deep Learning System Reproducibility
                
              </h1>
              
              

              

              
              
              
            </div>
          </div>
          
        </div>
        
        
      </div>
      
    </div>
  </div>
</header>



    
<div class="container" role="main">
  <div class="row">
    <div class="col-lg-8 offset-lg-2 col-md-10 offset-md-1 ">

      <div class="card-image card-image-blog p-0">
        
        


        
      </div>
    </div>

    <div class="col-lg-8 offset-lg-2 col-md-10 offset-md-1 pt-4">
      <article role="main" class="blog-post">
        <h1 id="defeating-nondeterminism-in-llm-inference-a-breakthrough-in-deep-learning-system-reproducibility">Defeating Nondeterminism in LLM Inference: A Breakthrough in Deep Learning System Reproducibility</h1>
<h2 id="introduction">Introduction</h2>
<p><strong>Reproducibility</strong> stands as one of the fundamental pillars of scientific research. However, when dealing with large language models (LLMs), achieving reproducible results has proven extraordinarily challenging. Even when we set the temperature parameter to 0 (greedy sampling), which should theoretically produce deterministic results, LLM inference still exhibits nondeterministic behavior.</p>
<p>Recently, the Thinking Machines team published <a href="https://thinkingmachines.ai/blog/defeating-nondeterminism-in-llm-inference/">groundbreaking research</a> that deeply investigates the root causes of nondeterminism in LLM inference and proposes effective solutions. This article provides an in-depth analysis of the core principles and methods of this research.</p>
<h2 id="the-nature-of-the-problem-floating-point-non-associativity">The Nature of the Problem: Floating-Point Non-Associativity</h2>
<h3 id="the-original-sin-of-floating-point-operations">The &ldquo;Original Sin&rdquo; of Floating-Point Operations</h3>
<p>To understand the root of nondeterminism, we must first grasp the concept of <strong>floating-point non-associativity</strong>. In floating-point arithmetic:</p>
<p>$$(a + b) + c \neq a + (b + c)$$</p>
<p>This seemingly simple mathematical property is actually the fundamental cause of nondeterminism in large language model inference.</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#998;font-style:italic"># Simple example of floating-point non-associativity</span>
</span></span><span style="display:flex;"><span>(<span style="color:#099">0.1</span> <span style="font-weight:bold">+</span> <span style="color:#099">1e20</span>) <span style="font-weight:bold">-</span> <span style="color:#099">1e20</span>  <span style="color:#998;font-style:italic"># Result: 0</span>
</span></span><span style="display:flex;"><span><span style="color:#099">0.1</span> <span style="font-weight:bold">+</span> (<span style="color:#099">1e20</span> <span style="font-weight:bold">-</span> <span style="color:#099">1e20</span>)  <span style="color:#998;font-style:italic"># Result: 0.1</span>
</span></span></code></pre></div><h3 id="dynamic-precision-and-information-loss">Dynamic Precision and Information Loss</h3>
<p>Floating-point systems balance numerical range and precision through &ldquo;dynamic precision.&rdquo; When adding two floating-point numbers with different exponents, the system must discard some precision information:</p>
<ul>
<li>1230 ($1.23 \times 10^2$) + 23.4 ($2.34 \times 10^1$) = 1253.4</li>
<li>But due to maintaining only 3 digits of precision, the result is truncated to 1250 ($1.25 \times 10^2$)</li>
</ul>
<p>This means that <strong>every time floating-point numbers are added in different orders, completely different results may be obtained</strong>.</p>
<h2 id="limitations-of-traditional-explanations">Limitations of Traditional Explanations</h2>
<h3 id="insufficiency-of-the-concurrency--floating-point-hypothesis">Insufficiency of the &ldquo;Concurrency + Floating-Point&rdquo; Hypothesis</h3>
<p>For a long time, the academic community has generally attributed the nondeterminism in LLM inference to the &ldquo;concurrency + floating-point&rdquo; hypothesis:</p>
<blockquote>
<p>Due to the parallel computing characteristics of GPUs, the completion order of different threads is nondeterministic, leading to inconsistent floating-point accumulation orders.</p>
</blockquote>
<p>However, this research reveals the limitations of this hypothesis:</p>
<ol>
<li><strong>GPU matrix multiplication is deterministic</strong>: Even highly parallel matrix multiplication operations can produce bit-level identical results when repeatedly executed on the same data</li>
<li><strong>Not all concurrent operations lead to nondeterminism</strong>: The key lies in specific implementation methods, not concurrency itself</li>
</ol>
<h2 id="the-real-culprit-batch-non-invariance">The Real Culprit: Batch Non-Invariance</h2>
<h3 id="core-discovery">Core Discovery</h3>
<p>The research team discovered that the true root of LLM inference nondeterminism is <strong>batch non-invariance</strong>. Specifically manifested as:</p>
<ul>
<li>The same data produces different numerical results under different batch sizes</li>
<li>These differences accumulate and amplify during the inference process</li>
<li>Ultimately leading to completely different output sequences</li>
</ul>
<h3 id="problems-with-chunked-reduction-strategies">Problems with Chunked Reduction Strategies</h3>
<p>In attention mechanism calculations, when query length is small (such as during the decoding phase), chunked reduction strategies are needed to fully utilize GPU parallelism. The problem lies in:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#998;font-style:italic"># Problem example: Dynamic chunking strategy</span>
</span></span><span style="display:flex;"><span><span style="color:#998;font-style:italic"># KV length = 1000, requires 4 chunks</span>
</span></span><span style="display:flex;"><span><span style="color:#998;font-style:italic"># Each core processes 250 elements</span>
</span></span><span style="display:flex;"><span><span style="color:#998;font-style:italic"># But chunk count depends on batch size and query length</span>
</span></span></code></pre></div><p>This dynamic chunking strategy breaks batch invariance because:</p>
<ul>
<li>Chunking strategy depends on the current number of queries being processed</li>
<li>Different requests may trigger different chunking strategies</li>
<li>Leading to differences in floating-point accumulation order</li>
</ul>
<h2 id="solution-batch-invariant-kernels">Solution: Batch-Invariant Kernels</h2>
<h3 id="fixed-size-chunking-strategy">Fixed-Size Chunking Strategy</h3>
<p>The core solution proposed by the research team is to adopt a <strong>fixed-size chunking strategy</strong>:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#998;font-style:italic"># Solution: Fixed-size chunking</span>
</span></span><span style="display:flex;"><span><span style="color:#998;font-style:italic"># Regardless of KV length, each chunk is fixed at 256 elements</span>
</span></span><span style="display:flex;"><span><span style="color:#998;font-style:italic"># KV length = 1000 → 3 chunks of 256 + 1 chunk of 232</span>
</span></span><span style="display:flex;"><span><span style="color:#998;font-style:italic"># KV length = 512  → 2 chunks of 256</span>
</span></span></code></pre></div><p>Advantages of this strategy:</p>
<ul>
<li><strong>Batch invariance</strong>: Same reduction order is executed regardless of how many tokens are processed</li>
<li><strong>Reproducibility</strong>: Same input always produces same output</li>
<li><strong>Performance preservation</strong>: Still able to fully utilize GPU parallelism</li>
</ul>
<h3 id="implementation-details">Implementation Details</h3>
<p>The team achieved deterministic inference through the following technologies:</p>
<ol>
<li><strong>torch.Library integration</strong>: Non-invasive replacement of PyTorch operators</li>
<li><strong>FlexAttention backend</strong>: Implementation based on vLLM&rsquo;s FlexAttention</li>
<li><strong>Batch-invariant kernels</strong>: Specially designed kernels ensuring numerical stability</li>
</ol>
<h2 id="experimental-results-and-verification">Experimental Results and Verification</h2>
<h3 id="nondeterminism-level-assessment">Nondeterminism Level Assessment</h3>
<p>Testing with the Qwen/Qwen3-235B model:</p>
<ul>
<li><strong>Traditional method</strong>: 1000 identical prompts generated 80 different results</li>
<li><strong>Deterministic method</strong>: 1000 identical prompts generated completely identical results</li>
</ul>
<p>Notably, even with the nondeterministic method, the first 102 tokens were completely identical, with differences beginning to appear from the 103rd token.</p>
<h3 id="performance-impact">Performance Impact</h3>
<table>
  <thead>
      <tr>
          <th>Configuration</th>
          <th>Time (seconds)</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>vLLM Default</td>
          <td>26</td>
      </tr>
      <tr>
          <td>Unoptimized Deterministic vLLM</td>
          <td>55</td>
      </tr>
      <tr>
          <td>Improved Attention Kernel</td>
          <td>42</td>
      </tr>
  </tbody>
</table>
<p>While deterministic inference incurs some performance overhead, it remains within acceptable ranges.</p>
<h3 id="breakthrough-in-reinforcement-learning">Breakthrough in Reinforcement Learning</h3>
<p>More importantly, this research solves a critical problem in reinforcement learning:</p>
<ul>
<li><strong>Traditional problem</strong>: Numerical differences between training and inference lead to &ldquo;fake on-policy&rdquo; reinforcement learning</li>
<li><strong>Solution</strong>: Deterministic inference makes true on-policy reinforcement learning possible</li>
<li><strong>Verification results</strong>: In RLVR experiments, the deterministic method achieved 0 KL divergence, indicating complete consistency between training and sampling policies</li>
</ul>
<h2 id="technical-implementation-and-open-source-contributions">Technical Implementation and Open Source Contributions</h2>
<h3 id="open-source-resources">Open Source Resources</h3>
<p>The research team provided complete implementations:</p>
<ul>
<li><strong>Batch-invariant operations library</strong>: <a href="https://github.com/thinking-machines-lab/batch-invariant-ops">thinking-machines-lab/batch-invariant-ops</a></li>
<li><strong>vLLM deterministic mode examples</strong>: Directly runnable code demonstrations</li>
</ul>
<h3 id="core-code-structure">Core Code Structure</h3>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#998;font-style:italic"># Core idea of batch-invariant kernels</span>
</span></span><span style="display:flex;"><span><span style="font-weight:bold">def</span> <span style="color:#900;font-weight:bold">batch_invariant_reduction</span>(data, reduction_dim):
</span></span><span style="display:flex;"><span>    <span style="color:#998;font-style:italic"># Fixed chunk size, not fixed chunk count</span>
</span></span><span style="display:flex;"><span>    fixed_chunk_size <span style="font-weight:bold">=</span> <span style="color:#099">256</span>
</span></span><span style="display:flex;"><span>    chunks <span style="font-weight:bold">=</span> split_into_fixed_size_chunks(data, fixed_chunk_size)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#998;font-style:italic"># Ensure consistency of reduction order</span>
</span></span><span style="display:flex;"><span>    result <span style="font-weight:bold">=</span> deterministic_reduce(chunks)
</span></span><span style="display:flex;"><span>    <span style="font-weight:bold">return</span> result
</span></span></code></pre></div><h2 id="significance-for-ai-research">Significance for AI Research</h2>
<h3 id="enhancement-of-scientific-rigor">Enhancement of Scientific Rigor</h3>
<p>The value of this research lies not only in technical breakthroughs but also in its contribution to the scientific rigor of AI research:</p>
<ol>
<li><strong>Reproducibility</strong>: Researchers can completely reproduce experimental results</li>
<li><strong>Debugging capability</strong>: Ability to precisely locate and fix numerical issues</li>
<li><strong>System understanding</strong>: Deep understanding of the complexity of modern GPU computing systems</li>
</ol>
<h3 id="practical-application-value">Practical Application Value</h3>
<ul>
<li><strong>Model deployment</strong>: Ensuring consistent behavior in production environments</li>
<li><strong>A/B testing</strong>: Eliminating the impact of randomness on experimental results</li>
<li><strong>Reinforcement learning</strong>: Enabling true on-policy learning</li>
</ul>
<h2 id="conclusion-and-outlook">Conclusion and Outlook</h2>
<p>The research by the Thinking Machines team reveals the true root of nondeterminism in LLM inference and provides practical solutions. This work not only solves technical problems but more importantly enhances the scientific rigor of the entire AI research field.</p>
<h3 id="key-insights">Key Insights</h3>
<ol>
<li><strong>Don&rsquo;t accept &ldquo;this is normal&rdquo;</strong>: When facing nondeterminism issues, we should dig deep into root causes</li>
<li><strong>Importance of systems thinking</strong>: Understanding interaction effects in multi-layered abstract systems</li>
<li><strong>Integration of engineering and science</strong>: Validating scientific hypotheses through engineering practice</li>
</ol>
<h3 id="future-directions">Future Directions</h3>
<ul>
<li><strong>Performance optimization</strong>: Further optimizing the performance of deterministic kernels</li>
<li><strong>Broader applicability</strong>: Extending methods to more model architectures</li>
<li><strong>Standardization promotion</strong>: Promoting deterministic inference as an industry standard</li>
</ul>
<p>This research reminds us that in today&rsquo;s rapid AI development, we still need to maintain attention to fundamental issues and solve seemingly complex engineering problems through rigorous scientific methods. The implementation of deterministic inference is not only a technical achievement but also a persistence and practice of scientific methodology.</p>
<hr>
<p><em>References:</em></p>
<ul>
<li><a href="https://thinkingmachines.ai/blog/defeating-nondeterminism-in-llm-inference/">He, Horace and Thinking Machines Lab, &ldquo;Defeating Nondeterminism in LLM Inference&rdquo;, Thinking Machines Lab: Connectionism, Sep 2025</a></li>
<li><a href="https://github.com/thinking-machines-lab/batch-invariant-ops">GitHub: batch-invariant-ops</a></li>
</ul>

      </article>
    </div>
  </div>

  
  <div class="row">
    <div class="col-lg-8 offset-lg-2 col-md-10 offset-md-1">
      <hr class="m-0"/>
    </div>
    <div class="col-lg-8 offset-lg-2 col-md-10 offset-md-1 pt-2">
      
      <div class="blog-tags">
        
        <a href="https://jiufengblog.firebaseapp.com/tags/machine-learning/">machine-learning</a>
        
        <a href="https://jiufengblog.firebaseapp.com/tags/llm/">llm</a>
        
        <a href="https://jiufengblog.firebaseapp.com/tags/determinism/">determinism</a>
        
        <a href="https://jiufengblog.firebaseapp.com/tags/reproducibility/">reproducibility</a>
        
        <a href="https://jiufengblog.firebaseapp.com/tags/research/">research</a>
        
      </div>
      
    </div>

    <div class="col-lg-8 offset-lg-2 col-md-10 offset-md-1 pt-4">
      
      <section id="social-share">
        <div class="list-inline footer-links">
          

<div>
  <p>Share with friends</p>
</div>
<div class="share-box" aria-hidden="true">
  <ul class="share">

    
    <li>
      <a href="//www.facebook.com/sharer/sharer.php?u=https%3a%2f%2fjiufengblog.firebaseapp.com%2fblogs%2f2025%2fsep%2fdefeating-llm-nondeterminism%2f" target="_blank" title="Share on Facebook">
        <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" class="bi bi-facebook" viewBox="0 0 16 16">
          <path
            d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58 0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876 0 1.791.157 1.791.157v1.98h-1.009c-.993 0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951z" />
        </svg>
      </a>
    </li>
    
    <li>
      <a href="//twitter.com/share?url=https%3a%2f%2fjiufengblog.firebaseapp.com%2fblogs%2f2025%2fsep%2fdefeating-llm-nondeterminism%2f&amp;text=Defeating%20Nondeterminism%20in%20LLM%20Inference%3a%20A%20Breakthrough%20in%20Deep%20Learning%20System%20Reproducibility&amp;via=map%5b%5d"
        target="_blank" title="Share on Twitter">
        <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" class="bi bi-twitter-x" viewBox="0 0 16 16">
          <path
            d="M12.6.75h2.454l-5.36 6.142L16 15.25h-4.937l-3.867-5.07-4.425 5.07H.316l5.733-6.57L0 .75h5.063l3.495 4.633L12.601.75Zm-.86 13.028h1.36L4.323 2.145H2.865l8.875 11.633Z" />
        </svg>
      </a>
    </li>


    
    <li>
      <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fjiufengblog.firebaseapp.com%2fblogs%2f2025%2fsep%2fdefeating-llm-nondeterminism%2f&amp;title=Defeating%20Nondeterminism%20in%20LLM%20Inference%3a%20A%20Breakthrough%20in%20Deep%20Learning%20System%20Reproducibility"
        target="_blank" title="Share on LinkedIn">
        <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" class="bi bi-linkedin" viewBox="0 0 16 16">
          <path
            d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854V1.146zm4.943 12.248V6.169H2.542v7.225h2.401zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248-.822 0-1.359.54-1.359 1.248 0 .694.521 1.248 1.327 1.248h.016zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016a5.54 5.54 0 0 1 .016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225h2.4z" />
        </svg>
      </a>
    </li>

    <li>
      <a target="_blank" rel="noopener noreferrer" aria-label="share Defeating Nondeterminism in LLM Inference: A Breakthrough in Deep Learning System Reproducibility on reddit"
        href="https://reddit.com/submit?url=https%3a%2f%2fjiufengblog.firebaseapp.com%2fblogs%2f2025%2fsep%2fdefeating-llm-nondeterminism%2f&title=Defeating%20Nondeterminism%20in%20LLM%20Inference%3a%20A%20Breakthrough%20in%20Deep%20Learning%20System%20Reproducibility">
        <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" class="bi bi-reddit"
          viewBox="0 0 16 16">
          <path
            d="M6.167 8a.831.831 0 0 0-.83.83c0 .459.372.84.83.831a.831.831 0 0 0 0-1.661zm1.843 3.647c.315 0 1.403-.038 1.976-.611a.232.232 0 0 0 0-.306.213.213 0 0 0-.306 0c-.353.363-1.126.487-1.67.487-.545 0-1.308-.124-1.671-.487a.213.213 0 0 0-.306 0 .213.213 0 0 0 0 .306c.564.563 1.652.61 1.977.61zm.992-2.807c0 .458.373.83.831.83.458 0 .83-.381.83-.83a.831.831 0 0 0-1.66 0z" />
          <path
            d="M16 8A8 8 0 1 1 0 8a8 8 0 0 1 16 0zm-3.828-1.165c-.315 0-.602.124-.812.325-.801-.573-1.9-.945-3.121-.993l.534-2.501 1.738.372a.83.83 0 1 0 .83-.869.83.83 0 0 0-.744.468l-1.938-.41a.203.203 0 0 0-.153.028.186.186 0 0 0-.086.134l-.592 2.788c-1.24.038-2.358.41-3.17.992-.21-.2-.496-.324-.81-.324a1.163 1.163 0 0 0-.478 2.224c-.02.115-.029.23-.029.353 0 1.795 2.091 3.256 4.669 3.256 2.577 0 4.668-1.451 4.668-3.256 0-.114-.01-.238-.029-.353.401-.181.688-.592.688-1.069 0-.65-.525-1.165-1.165-1.165z" />
        </svg>
      </a>
    </li>

    
    


    
    <li>
      <a href="whatsapp://send?text=https%3a%2f%2fjiufengblog.firebaseapp.com%2fblogs%2f2025%2fsep%2fdefeating-llm-nondeterminism%2f&amp;description=Defeating%20Nondeterminism%20in%20LLM%20Inference%3a%20A%20Breakthrough%20in%20Deep%20Learning%20System%20Reproducibility" target="_blank" rel="noopener"
        title="Share on WhatsApp">
        <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" class="bi bi-whatsapp" viewBox="0 0 16 16">
          <path
            d="M13.601 2.326A7.854 7.854 0 0 0 7.994 0C3.627 0 .068 3.558.064 7.926c0 1.399.366 2.76 1.057 3.965L0 16l4.204-1.102a7.933 7.933 0 0 0 3.79.965h.004c4.368 0 7.926-3.558 7.93-7.93A7.898 7.898 0 0 0 13.6 2.326zM7.994 14.521a6.573 6.573 0 0 1-3.356-.92l-.24-.144-2.494.654.666-2.433-.156-.251a6.56 6.56 0 0 1-1.007-3.505c0-3.626 2.957-6.584 6.591-6.584a6.56 6.56 0 0 1 4.66 1.931 6.557 6.557 0 0 1 1.928 4.66c-.004 3.639-2.961 6.592-6.592 6.592zm3.615-4.934c-.197-.099-1.17-.578-1.353-.646-.182-.065-.315-.099-.445.099-.133.197-.513.646-.627.775-.114.133-.232.148-.43.05-.197-.1-.836-.308-1.592-.985-.59-.525-.985-1.175-1.103-1.372-.114-.198-.011-.304.088-.403.087-.088.197-.232.296-.346.1-.114.133-.198.198-.33.065-.134.034-.248-.015-.347-.05-.099-.445-1.076-.612-1.47-.16-.389-.323-.335-.445-.34-.114-.007-.247-.007-.38-.007a.729.729 0 0 0-.529.247c-.182.198-.691.677-.691 1.654 0 .977.71 1.916.81 2.049.098.133 1.394 2.132 3.383 2.992.47.205.84.326 1.129.418.475.152.904.129 1.246.08.38-.058 1.171-.48 1.338-.943.164-.464.164-.86.114-.943-.049-.084-.182-.133-.38-.232z" />
        </svg>
      </a>
    </li>
  </ul>
</div>

        </div>
      </section>
      
    </div>

    
    <div class="col-lg-8 offset-lg-2 col-md-10 offset-md-1 mt-3">
      <div class="card">
        <div class="row no-gutters">

          
          <div class="col-md-2 ">
            <div class="card-body ">
              
               
                <img src="/img/author/author_bottom.jpg" class="img-responsive img-50 img-round" alt="">
              
            </div>
          </div>
         


          <div class="col-md-10">
            <div class="card-body p-1.1">
              <p class="p-0 m-0"><small class="text-muted">Written By</small></p>
              <p class="card-text fs-5 m-0">
                 
                
                Jiufeng Li
                

              </p>

               
                <p class="card-text fs-6  m-0">Build yourself and believe in yourself.</p>
              
            </div>
          </div>
        </div>
      </div>
    </div>
    

    <div class="col-lg-8 offset-lg-2 col-md-12 offset-md-1 pt-4">
      
      <ul class="list-group list-group-horizontal" style="flex-direction: row">
        


        
        <li class="list-group-item ms-auto b-0 p-0">
          <a type="button" class="btn btn-dark" role="button" href="https://jiufengblog.firebaseapp.com/blogs/2025/sep/how-people-use-chatgpt/"
            data-toggle="tooltip" data-placement="top" title="How People Are Using ChatGPT: Insights from OpenAI&#39;s Latest Usage Analysis">Next Post
            &rarr;</a>
        </li>
        
      </ul>
      
    </div>

    <div class="col-lg-8 offset-lg-2 col-md-10 offset-md-1 pt-4">
    </div>
  </div>
  
</div>

<div class="">
  
  
  
  
  

  
  <div class="container">
    <div class="row">
      <div class="col-lg-12 col-md-12 mt-3">
        <h3>Read More</h3>
        <hr />
      </div>

      
      

      
<div class="compact-blog-card h-100">
  <a href="https://jiufengblog.firebaseapp.com/blogs/2025/sep/deepseek-r1-nature-breakthrough/" class="text-decoration-none">
    <div class="card compact-card border-0 shadow-sm">
      <div class="row g-0 h-100">
        
        
        <div class="col-4">
          
          <div class="card-img-wrapper h-100 d-flex align-items-center justify-content-center" 
               style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);">
            <i class="bi bi-journal-text text-white" style="font-size: 1.5rem; opacity: 0.9;"></i>
          </div>
        </div>

        
        <div class="col-8">
          <div class="card-body p-3 h-100 d-flex flex-column">
            
            
            
            <div class="mb-2">
              
              <span class="badge bg-primary bg-opacity-10 text-primary" style="font-size: 0.7rem;">AI Research</span>
              
            </div>
            

            
            <h6 class="card-title fw-bold mb-2 text-dark lh-sm" 
                style="display: -webkit-box; -webkit-line-clamp: 2; -webkit-box-orient: vertical; overflow: hidden; font-size: 0.95rem;">
              DeepSeek-R1 Makes Nature Cover: How Pure Reinforcement Learning Revolutionizes LLM Reasoning
            </h6>

            
            <p class="card-text text-muted flex-grow-1 mb-3" 
               style="font-size: 0.8rem; line-height: 1.4; display: -webkit-box; -webkit-line-clamp: 3; -webkit-box-orient: vertical; overflow: hidden;">
              
                An in-depth analysis of DeepSeek-R1&#39;s groundbreaking Nature publication: achieving GPT-4 level performance with pure reinforcement …
              
            </p>

            
            <div class="mt-auto pt-3 pb-2">
              <div class="d-flex align-items-center justify-content-between">
                <small class="text-muted d-flex align-items-center" style="flex: 1; min-width: 0;">
                  <i class="bi bi-calendar3 me-1" style="font-size: 0.7rem; flex-shrink: 0;"></i>
                  <span class="meta-date-text" style="font-size: 0.75rem; white-space: nowrap; overflow: hidden; text-overflow: ellipsis;">September 21, 2025</span>
                </small>
                <small class="text-muted d-flex align-items-center ms-2" style="flex-shrink: 0;">
                  <i class="bi bi-clock me-1" style="font-size: 0.7rem;"></i>
                  <span class="meta-time-text" style="font-size: 0.75rem;">6min</span>
                </small>
              </div>
            </div>

          </div>
        </div>
      </div>
    </div>
  </a>
</div>

<style>
.compact-blog-card {
  height: 200px !important;
}

.compact-card {
  height: 200px;
  transition: all 0.3s ease;
  border-radius: 8px;
  overflow: hidden;
}

.compact-card:hover {
  transform: translateY(-3px);
  box-shadow: 0 6px 20px rgba(0,0,0,0.15) !important;
}

.compact-card:hover .card-img {
  transform: scale(1.1);
}

.compact-blog-card a:hover {
  text-decoration: none;
}

.compact-blog-card .card-title {
  transition: color 0.2s ease;
}

.compact-blog-card:hover .card-title {
  color: #667eea !important;
}

.card-img-wrapper {
  border-radius: 8px 0 0 8px;
}

@media (max-width: 768px) {
  .compact-blog-card {
    height: 180px !important;
  }
  
  .compact-card {
    height: 180px;
  }
  
  .compact-card .card-body {
    padding: 0.75rem !important;
  }
  
  .compact-card .card-title {
    font-size: 0.85rem !important;
  }
  
  .compact-card .card-text {
    font-size: 0.75rem !important;
  }
  
  .compact-card .meta-date-text {
    font-size: 0.7rem !important;
  }
  
  .compact-card .meta-time-text {
    font-size: 0.7rem !important;
  }
}
</style>

      
    </div>
  </div>
  
  

  

</div>

    


<footer>

  <div class="container">
    <div class="row">
      <div class="col-md-12">
        <ul
          class="list-inline list-group list-group-horizontal text-center footer-links d-flex justify-content-center flex-row">

          
          
        </ul>
      </div>
    </div>

    <div class="row">
      <div class="col-md-12">
        <p class="credits copyright text-muted">
          

          &nbsp;&nbsp;&copy;
          
          2025
          

          
          &nbsp;&bull;&nbsp;
          <a href="https://jiufengblog.firebaseapp.com/">Feng</a>
          
        </p>
        
        <p class="credits theme-by text-muted">
          Powered by <a href="https://gohugo.io">Hugo</a>, <a href="https://github.com/binokochumolvarghese/lightbi-hugo">Lightbi</a>&nbsp;and <a href="https://firebase.google.com/?_gl=1*iwdk9w*_up*MQ..&gclid=CjwKCAjwg-24BhB_EiwA1ZOx8unyg5rIWPOxlt7co1MF6j3y9dvE6akQQylntoWf7XjIi7nUHhyRSRoCuFAQAvD_BwE&gclsrc=aw.ds">Google Firebase</a>&nbsp; 
          
        </p>
      </div>
    </div>
  </div>
</footer><script src="https://jiufengblog.firebaseapp.com/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
<script src="https://jiufengblog.firebaseapp.com/js/highlight.min.js"></script>
<script> hljs.initHighlightingOnLoad(); </script>
<script> $(document).ready(function () { $("pre.chroma").css("padding", "0"); }); </script>

    
  </body>
</html>


<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AI Research on Feng</title>
    <link>https://jiufengblog.firebaseapp.com/categories/ai-research/</link>
    <description>Recent content in AI Research on Feng</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <managingEditor>lijiufeng97@gmail.com (Jiufeng Li)</managingEditor>
    <webMaster>lijiufeng97@gmail.com (Jiufeng Li)</webMaster>
    <lastBuildDate>Tue, 17 Sep 2024 16:00:00 +0100</lastBuildDate>
    <atom:link href="https://jiufengblog.firebaseapp.com/categories/ai-research/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>The Great AI Divide: ChatGPT vs Claude Usage Patterns Reveal Distinct User Preferences</title>
      <link>https://jiufengblog.firebaseapp.com/blogs/2025/sep/chatgpt-vs-claude-usage-patterns/</link>
      <pubDate>Tue, 17 Sep 2024 16:00:00 +0100</pubDate><author>lijiufeng97@gmail.com (Jiufeng Li)</author>
      <guid>https://jiufengblog.firebaseapp.com/blogs/2025/sep/chatgpt-vs-claude-usage-patterns/</guid>
      <description>&lt;h1 id=&#34;the-great-ai-divide-chatgpt-vs-claude-usage-patterns-reveal-distinct-user-preferences&#34;&gt;The Great AI Divide: ChatGPT vs Claude Usage Patterns Reveal Distinct User Preferences&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;In an unprecedented move, both OpenAI and Anthropic have released comprehensive usage studies of their flagship AI assistants, ChatGPT and Claude. These &lt;a href=&#34;https://fortune.com/2025/09/15/openai-chatgpt-claude-anthropic-work-personal-use-new-data/&#34;&gt;dueling analyses&lt;/a&gt; provide fascinating insights into how different AI models are carving out distinct niches in the rapidly evolving landscape of artificial intelligence.&lt;/p&gt;</description>
    </item>
    <item>
      <title>How People Are Using ChatGPT: Insights from OpenAI&#39;s Latest Usage Analysis</title>
      <link>https://jiufengblog.firebaseapp.com/blogs/2025/sep/how-people-use-chatgpt/</link>
      <pubDate>Mon, 16 Sep 2024 14:00:00 +0100</pubDate><author>lijiufeng97@gmail.com (Jiufeng Li)</author>
      <guid>https://jiufengblog.firebaseapp.com/blogs/2025/sep/how-people-use-chatgpt/</guid>
      <description>&lt;h1 id=&#34;how-people-are-using-chatgpt-insights-from-openais-latest-usage-analysis&#34;&gt;How People Are Using ChatGPT: Insights from OpenAI&amp;rsquo;s Latest Usage Analysis&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;Understanding how people actually use artificial intelligence tools provides crucial insights into the technology&amp;rsquo;s real-world impact and future trajectory. OpenAI recently released a comprehensive analysis of ChatGPT usage patterns, examining millions of conversations to understand how people interact with their flagship AI assistant.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Defeating Nondeterminism in LLM Inference: A Breakthrough in Deep Learning System Reproducibility</title>
      <link>https://jiufengblog.firebaseapp.com/blogs/2024/sep/defeating-llm-nondeterminism/</link>
      <pubDate>Sun, 15 Sep 2024 10:00:00 +0100</pubDate><author>lijiufeng97@gmail.com (Jiufeng Li)</author>
      <guid>https://jiufengblog.firebaseapp.com/blogs/2024/sep/defeating-llm-nondeterminism/</guid>
      <description>&lt;h1 id=&#34;defeating-nondeterminism-in-llm-inference-a-breakthrough-in-deep-learning-system-reproducibility&#34;&gt;Defeating Nondeterminism in LLM Inference: A Breakthrough in Deep Learning System Reproducibility&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Reproducibility&lt;/strong&gt; stands as one of the fundamental pillars of scientific research. However, when dealing with large language models (LLMs), achieving reproducible results has proven extraordinarily challenging. Even when we set the temperature parameter to 0 (greedy sampling), which should theoretically produce deterministic results, LLM inference still exhibits nondeterministic behavior.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Defeating Nondeterminism in LLM Inference: A Breakthrough in Deep Learning System Reproducibility</title>
      <link>https://jiufengblog.firebaseapp.com/blogs/2025/sep/defeating-llm-nondeterminism/</link>
      <pubDate>Sun, 15 Sep 2024 10:00:00 +0100</pubDate><author>lijiufeng97@gmail.com (Jiufeng Li)</author>
      <guid>https://jiufengblog.firebaseapp.com/blogs/2025/sep/defeating-llm-nondeterminism/</guid>
      <description>&lt;h1 id=&#34;defeating-nondeterminism-in-llm-inference-a-breakthrough-in-deep-learning-system-reproducibility&#34;&gt;Defeating Nondeterminism in LLM Inference: A Breakthrough in Deep Learning System Reproducibility&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Reproducibility&lt;/strong&gt; stands as one of the fundamental pillars of scientific research. However, when dealing with large language models (LLMs), achieving reproducible results has proven extraordinarily challenging. Even when we set the temperature parameter to 0 (greedy sampling), which should theoretically produce deterministic results, LLM inference still exhibits nondeterministic behavior.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>

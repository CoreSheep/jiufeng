[{"categories":["AI Research"],"content":"击败LLM推理中的非确定性：深度学习系统可重现性的突破 引言 在科学研究的基石中，可重现性占据着至关重要的地位。然而，当我们面对大语言模型（LLM）时，获得可重现的结果却异常困难。即使我们将温度参数调整到0（贪心采样），理论上应该产生确定性的结果，但LLM推理仍然表现出非确定性行为。\n最近，Thinking Machines团队在这篇开创性研究中深入探讨了LLM推理非确定性的根本原因，并提出了有效的解决方案。本文将深入解析这项研究的核心原理和方法。\n问题的本质：浮点数非结合性 浮点数运算的\"原罪\" 要理解非确定性的根源，我们首先需要了解浮点数非结合性的概念。在浮点数运算中：\n$$(a + b) + c \\neq a + (b + c)$$\n这个看似简单的数学性质实际上是大语言模型推理非确定性的根本原因。\n# 浮点数非结合性的简单示例 (0.1 + 1e20) - 1e20 # 结果: 0 0.1 + (1e20 - 1e20) # 结果: 0.1 动态精度与信息丢失 浮点数系统通过\"动态精度\"来平衡数值范围和精度。当我们相加两个具有不同指数的浮点数时，系统必须丢弃一些精度信息：\n1230 ($1.23 \\times 10^2$) + 23.4 ($2.34 \\times 10^1$) = 1253.4 但由于只能保持3位精度，结果被截断为 1250 ($1.25 \\times 10^2$) 这意味着每次以不同顺序相加浮点数时，都可能得到完全不同的结果。\n传统解释的局限性 “并发+浮点数\"假设的不足 长期以来，学术界普遍认为LLM推理的非确定性源于\"并发+浮点数\"假设：\n由于GPU的并行计算特性，不同线程的完成顺序是非确定性的，导致浮点数累加顺序的不一致。\n然而，这项研究揭示了这一假设的局限性：\nGPU矩阵乘法是确定性的：即使是高度并行的矩阵乘法操作，在相同数据上重复执行也能产生位级相同的结果 并非所有并发操作都导致非确定性：关键在于具体的实现方式，而非并发本身 真正的罪魁祸首：批处理非不变性 核心发现 研究团队发现，LLM推理非确定性的真正根源是批处理非不变性（batch non-invariance）。具体表现为：\n相同的数据在不同的批处理大小下会产生不同的数值结果 这种差异会随着推理过程的进行而累积放大 最终导致完全不同的输出序列 分片归约策略的问题 在注意力机制的计算中，当查询长度较小时（如解码阶段），需要采用分片归约策略来充分利用GPU并行性。问题在于：\n# 问题示例：动态分片策略 # KV长度 = 1000，需要4个分片 # 每个核心处理250个元素 # 但分片数量依赖于批处理大小和查询长度 这种动态分片策略破坏了批处理不变性，因为：\n分片策略依赖于当前处理的查询数量 不同请求可能触发不同的分片策略 导致浮点数累加顺序的差异 解决方案：批处理不变性内核 固定大小分片策略 研究团队提出的核心解决方案是采用固定大小分片策略：\n# 解决方案：固定大小分片 # 无论KV长度如何，每个分片固定为256个元素 # KV长度 = 1000 → 3个256分片 + 1个232分片 # KV长度 = 512 → 2个256分片 这种策略的优势：\n批处理不变性：无论处理多少token，都执行相同的归约顺序 可重现性：相同输入总是产生相同输出 性能保持：仍然能够充分利用GPU并行性 实现细节 团队通过以下技术实现了确定性推理：\ntorch.Library集成：以非侵入方式替换PyTorch操作符 FlexAttention后端：基于vLLM的FlexAttention实现 批处理不变内核：专门设计的内核确保数值稳定性 实验结果与验证 非确定性程度评估 使用Qwen/Qwen3-235B模型进行测试：\n传统方法：1000次相同提示生成80个不同的结果 确定性方法：1000次相同提示生成完全相同的结果 值得注意的是，即使是非确定性方法，前102个token也是完全相同的，差异从第103个token开始出现。\n性能影响 配置 时间（秒） vLLM默认 26 未优化确定性vLLM 55 改进注意力内核 42 虽然确定性推理会有一定的性能开销，但仍在可接受范围内。\n强化学习的突破 更重要的是，这项研究解决了强化学习中的一个关键问题：\n传统问题：训练和推理的数值差异导致\"假在线策略\"强化学习 解决方案：确定性推理使得真正的在线策略强化学习成为可能 验证结果：在RLVR实验中，确定性方法实现了0 KL散度，表明训练和采样策略完全一致 技术实现与开源贡献 开源资源 研究团队提供了完整的实现：\n批处理不变操作库：thinking-machines-lab/batch-invariant-ops vLLM确定性模式示例：可直接运行的代码演示 核心代码结构 # 批处理不变性内核的核心思想 def batch_invariant_reduction(data, reduction_dim): # 固定分片大小，而非固定分片数量 fixed_chunk_size = 256 chunks = split_into_fixed_size_chunks(data, fixed_chunk_size) # 确保归约顺序的一致性 result = deterministic_reduce(chunks) return result 对AI研究的意义 科学严谨性的提升 这项研究的价值不仅在于技术突破，更在于对AI研究科学严谨性的贡献：\n可重现性：研究者可以完全重现实验结果 调试能力：能够精确定位和修复数值问题 系统理解：深入理解现代GPU计算系统的复杂性 实际应用价值 模型部署：确保生产环境中的一致性行为 A/B测试：消除随机性对实验结果的影响 强化学习：实现真正的在线策略学习 结论与展望 Thinking Machines团队的研究为我们揭示了LLM推理非确定性的真正根源，并提供了切实可行的解决方案。这项工作不仅解决了技术问题，更重要的是提升了整个AI研究领域的科学严谨性。\n关键启示 不要接受\"这是正常的”：面对非确定性问题，我们应该深入挖掘根本原因 系统思维的重要性：理解多层抽象系统中的交互效应 工程与科学的结合：通过工程实践验证科学假设 未来方向 性能优化：进一步优化确定性内核的性能 更广泛的适用性：将方法扩展到更多模型架构 标准化推广：推动确定性推理成为行业标准 这项研究提醒我们，在AI快速发展的今天，我们仍然需要保持对基础问题的关注，通过严谨的科学方法来解决看似复杂的工程问题。确定性推理的实现不仅是一个技术成就，更是对科学方法论的坚持和践行。\n参考文献：\nHe, Horace and Thinking Machines Lab, “Defeating Nondeterminism in LLM Inference”, Thinking Machines Lab: Connectionism, Sep 2025 GitHub: batch-invariant-ops ","description":"深入解析Thinking Machines团队如何解决大语言模型推理中的非确定性问题，实现真正的可重现推理","tags":["machine-learning","llm","determinism","reproducibility","research"],"title":"击败LLM推理中的非确定性：深度学习系统可重现性的突破","uri":"/blogs/2024/sep/defeating-llm-nondeterminism/"},{"categories":["general"],"content":"This is a sample blog post to test the new Blogs section.\nThe Blogs section has been successfully added to replace the old Notes section.\nFeatures Clean blog layout Proper navigation Tag support Category support This demonstrates that the Blogs section is working correctly.\n","tags":["sample","blog"],"title":"Sample Blog Post","uri":"/blogs/2024/sample-blog/"},{"categories":["Testing"],"content":"测试博客文章：验证主页显示功能 这是一篇测试文章，用于验证主页是否能正确显示多篇博客文章。\n测试目的 验证主页能正确显示多篇博客文章 测试文章的排序和显示逻辑 确保点击Home后文章不会消失 测试内容 文章结构 正确的front matter配置 适当的日期设置 相关的标签和分类 技术要点 Hugo页面生成 主页布局逻辑 文章过滤机制 预期结果 这篇文章应该与其他博客文章一起显示在主页上，并且点击Home后应该保持可见。\n总结 通过创建这篇测试文章，我们可以验证主页的文章显示功能是否正常工作。\n","description":"这是一篇测试文章，用于验证主页是否能正确显示多篇博客文章","tags":["test","blog","hugo"],"title":"测试博客文章：验证主页显示功能","uri":"/blogs/2024/sep/test-blog/"}]

<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Determinism on Feng</title><link>https://jiufengblog.web.app/tags/determinism/</link><description>Recent content in Determinism on Feng</description><generator>Hugo</generator><language>en-us</language><managingEditor>lijiufeng97@gmail.com (Jiufeng Li)</managingEditor><webMaster>lijiufeng97@gmail.com (Jiufeng Li)</webMaster><lastBuildDate>Mon, 15 Sep 2025 10:00:00 +0100</lastBuildDate><atom:link href="https://jiufengblog.web.app/tags/determinism/index.xml" rel="self" type="application/rss+xml"/><item><title>Defeating Nondeterminism in LLM Inference: A Breakthrough in Deep Learning System Reproducibility</title><link>https://jiufengblog.web.app/blogs/2025/sep/defeating-llm-nondeterminism/</link><pubDate>Mon, 15 Sep 2025 10:00:00 +0100</pubDate><author>lijiufeng97@gmail.com (Jiufeng Li)</author><guid>https://jiufengblog.web.app/blogs/2025/sep/defeating-llm-nondeterminism/</guid><description>&lt;h1 id="defeating-nondeterminism-in-llm-inference-a-breakthrough-in-deep-learning-system-reproducibility">Defeating Nondeterminism in LLM Inference: A Breakthrough in Deep Learning System Reproducibility&lt;/h1>
&lt;h2 id="introduction">Introduction&lt;/h2>
&lt;p>&lt;strong>Reproducibility&lt;/strong> stands as one of the fundamental pillars of scientific research. However, when dealing with large language models (LLMs), achieving reproducible results has proven extraordinarily challenging. Even when we set the temperature parameter to 0 (greedy sampling), which should theoretically produce deterministic results, LLM inference still exhibits nondeterministic behavior.&lt;/p></description></item></channel></rss>